{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --> Importations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --> Importation dataset poeme de Victor Hugo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille du text :  127286\n",
      "Texte avant preprocessing :\n",
      " Parce que, jargonnant vêpres, jeûne et vigile,\n",
      "Exploitant Dieu qui rêve au fond du firmament,\n",
      "Vous a\n"
     ]
    }
   ],
   "source": [
    "with open(\"../../Datasets/VictorHugoPoems/victorhugo.txt\", \"r\", encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "    \n",
    "print(\"Taille du text : \", len(text))\n",
    "print(\"Texte avant preprocessing :\\n\", text[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --> Preprocessing du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille du vocabulaire :  57\n",
      "Vocabulaire :\n",
      " {'H', 'f', ' ', 'n', 'm', 'e', 'h', '.', 'o', 'E', 'p', 'R', 'k', 'A', 'N', 'J', 'w', 'a', 'U', 'Y', 'B', 's', 'S', 'V', 'r', 'b', 'c', 'X', 't', 'K', 'G', 'P', 'i', 'v', '\"', 'q', 'g', 'F', 'L', 'x', 'I', 'C', 'O', \"'\", 'l', 'Q', 'd', 'z', 'y', 'u', 'M', '\\n', ':', ',', 'T', 'D', 'j'}\n",
      "Texte formate :\n",
      " Parce que, jargonnant vepres, jeune et vigile,\n",
      "Exploitant Dieu qui reve au fond du firmament,\n",
      "Vous a\n"
     ]
    }
   ],
   "source": [
    "#Supprime les caracteres inutiles, les majuscules...\n",
    "import unidecode\n",
    "text = unidecode.unidecode(text)\n",
    "text.lower()\n",
    "text = text.replace(\"2\", \"\")\n",
    "text = text.replace(\"1\", \"\")\n",
    "text = text.replace(\"8\", \"\")\n",
    "text = text.replace(\"5\", \"\")\n",
    "text = text.replace(\">\", \"\")\n",
    "text = text.replace(\"<\", \"\")\n",
    "text = text.replace(\"!\", \"\")\n",
    "text = text.replace(\"?\", \"\")\n",
    "text = text.replace(\"-\", \"\")\n",
    "text = text.replace(\"$\", \"\")\n",
    "text = text.replace(\";\", \"\")\n",
    "text = text.strip()\n",
    "\n",
    "#Supprime tous les doublons\n",
    "vocab = set(text) \n",
    "\n",
    "#Affichage resultat\n",
    "print(\"Taille du vocabulaire : \", len(vocab))\n",
    "print(\"Vocabulaire :\\n\", vocab)\n",
    "print(\"Texte formate :\\n\", text[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab to int :\n",
      " {'H': 0, 'f': 1, ' ': 2, 'n': 3, 'm': 4, 'e': 5, 'h': 6, '.': 7, 'o': 8, 'E': 9, 'p': 10, 'R': 11, 'k': 12, 'A': 13, 'N': 14, 'J': 15, 'w': 16, 'a': 17, 'U': 18, 'Y': 19, 'B': 20, 's': 21, 'S': 22, 'V': 23, 'r': 24, 'b': 25, 'c': 26, 'X': 27, 't': 28, 'K': 29, 'G': 30, 'P': 31, 'i': 32, 'v': 33, '\"': 34, 'q': 35, 'g': 36, 'F': 37, 'L': 38, 'x': 39, 'I': 40, 'C': 41, 'O': 42, \"'\": 43, 'l': 44, 'Q': 45, 'd': 46, 'z': 47, 'y': 48, 'u': 49, 'M': 50, '\\n': 51, ':': 52, ',': 53, 'T': 54, 'D': 55, 'j': 56}\n",
      "Int to vocab :\n",
      " {0: 'H', 1: 'f', 2: ' ', 3: 'n', 4: 'm', 5: 'e', 6: 'h', 7: '.', 8: 'o', 9: 'E', 10: 'p', 11: 'R', 12: 'k', 13: 'A', 14: 'N', 15: 'J', 16: 'w', 17: 'a', 18: 'U', 19: 'Y', 20: 'B', 21: 's', 22: 'S', 23: 'V', 24: 'r', 25: 'b', 26: 'c', 27: 'X', 28: 't', 29: 'K', 30: 'G', 31: 'P', 32: 'i', 33: 'v', 34: '\"', 35: 'q', 36: 'g', 37: 'F', 38: 'L', 39: 'x', 40: 'I', 41: 'C', 42: 'O', 43: \"'\", 44: 'l', 45: 'Q', 46: 'd', 47: 'z', 48: 'y', 49: 'u', 50: 'M', 51: '\\n', 52: ':', 53: ',', 54: 'T', 55: 'D', 56: 'j'}\n"
     ]
    }
   ],
   "source": [
    "#On traduit maintenant tout le vocabulaire en nombre\n",
    "vocab_size = len(vocab)\n",
    "#Dictionnaire traduction\n",
    "vocab_to_int = {l:i for i,l in enumerate(vocab)} \n",
    "int_to_vocab = {i:l for i,l in enumerate(vocab)}\n",
    "#Affichage\n",
    "print(\"Vocab to int :\\n\", vocab_to_int)\n",
    "print(\"Int to vocab :\\n\", int_to_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31, 17, 24, 26, 5, 2, 35, 49, 5, 53, 2, 56, 17, 24, 36, 8, 3, 3, 17, 3, 28, 2, 33, 5, 10, 24, 5, 21, 53, 2, 56, 5, 49, 3, 5, 2, 5, 28, 2, 33, 32, 36, 32, 44, 5, 53, 51, 9, 39, 10, 44, 8, 32, 28, 17, 3, 28, 2, 55, 32, 5, 49, 2, 35, 49, 32, 2, 24, 5, 33, 5, 2, 17, 49, 2, 1, 8, 3, 46, 2, 46, 49, 2, 1, 32, 24, 4, 17, 4, 5, 3, 28, 53, 51, 23, 8, 49, 21, 2, 17]\n"
     ]
    }
   ],
   "source": [
    "#Le dictionnaire nous permet de traduire notre text en nombre\n",
    "encoded = [vocab_to_int[l] for l in text]\n",
    "encoded_sentence = encoded[:100]\n",
    "print(encoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['P', 'a', 'r', 'c', 'e', ' ', 'q', 'u', 'e', ',', ' ', 'j', 'a', 'r', 'g', 'o', 'n', 'n', 'a', 'n', 't', ' ', 'v', 'e', 'p', 'r', 'e', 's', ',', ' ', 'j', 'e', 'u', 'n', 'e', ' ', 'e', 't', ' ', 'v', 'i', 'g', 'i', 'l', 'e', ',', '\\n', 'E', 'x', 'p', 'l', 'o', 'i', 't', 'a', 'n', 't', ' ', 'D', 'i', 'e', 'u', ' ', 'q', 'u', 'i', ' ', 'r', 'e', 'v', 'e', ' ', 'a', 'u', ' ', 'f', 'o', 'n', 'd', ' ', 'd', 'u', ' ', 'f', 'i', 'r', 'm', 'a', 'm', 'e', 'n', 't', ',', '\\n', 'V', 'o', 'u', 's', ' ', 'a']\n"
     ]
    }
   ],
   "source": [
    "decoded_sentence = [int_to_vocab[i] for i in encoded_sentence]\n",
    "print(decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parce que, jargonnant vepres, jeune et vigile,\n",
      "Exploitant Dieu qui reve au fond du firmament,\n",
      "Vous a\n"
     ]
    }
   ],
   "source": [
    "decoded_sentence = \"\".join(decoded_sentence)\n",
    "print(decoded_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --> Creation des batchs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First inputs :  [31, 17, 24, 26, 5, 2, 35, 49, 5, 53]\n",
      "First targets :  [17, 24, 26, 5, 2, 35, 49, 5, 53, 2]\n"
     ]
    }
   ],
   "source": [
    "#Un batch = plusieurs sequences de mots\n",
    "#Ce qu'on peut faire lorsqu'on a un dataset comme cela, on peut prendre une sequence de quelques mots\n",
    "#Chaque lettre est une entree dont le target est la lettre suivante. \n",
    "#Une incoherence peut arriver lors de l'analyse de la premiere lettre d'une sequence\n",
    "#Car dans notre cellule RNN il n'a pas d'informations sur la lettre precedente car la memoire est nulle.\n",
    "#Au lieu de lui mettre un etat nulle on lui mets l'etat retenu du batch precendent.\n",
    "#On ne peut donc pas se permettre de selectionner des sequences aleatoires dans notre texte.\n",
    "#On va donc seprarer notre texte en chunks\n",
    "#Une epoch : un ensemble de batch\n",
    "def gen_batch(inputs, targets, seq_len, batch_size, noise=0):\n",
    "    \n",
    "    chunk_size = (len(inputs) -1) // batch_size\n",
    "    sequences_per_chunk = chunk_size // seq_len\n",
    "    \n",
    "    for seq in range(0, sequences_per_chunk):\n",
    "        batch_inputs = np.zeros((batch_size, seq_len))\n",
    "        batch_targets = np.zeros((batch_size, seq_len))\n",
    "        for b in range(0, batch_size):\n",
    "            fr = (b*chunk_size) + (seq*seq_len)\n",
    "            to = fr + seq_len\n",
    "            batch_inputs[b] = inputs[fr:to]\n",
    "            batch_targets[b] = inputs[fr+1:to+1]\n",
    "\n",
    "            if noise > 0: #\"noise\" aide le model a generaliser, evite l'overfitting\n",
    "                noise_indices = np.random.choice(seq_len, noise)\n",
    "                batch_inputs[b][noise_indices] = np.random.randint(0, vocab_size)\n",
    "\n",
    "        yield batch_inputs, batch_targets #Permet d'appeler la fonction dans la boucle\n",
    "            \n",
    "inputs, targets = encoded, encoded[1:]\n",
    "print(\"First inputs : \", inputs[:10])\n",
    "print(\"First targets : \", targets[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##################### Sans noise #####################\n",
      "\n",
      "----------------------Step  1 ----------------------\n",
      "\n",
      "Batch input :\n",
      " (32, 5) \n",
      "Batch target shape :\n",
      " (32, 5)\n",
      "\n",
      "Batch input :\n",
      " [31. 17. 24. 26.  5.] \n",
      "Batch target :\n",
      " [17. 24. 26.  5.  2.]\n",
      "\n",
      "----------------------Step  2 ----------------------\n",
      "\n",
      "Batch input :\n",
      " (32, 5) \n",
      "Batch target shape :\n",
      " (32, 5)\n",
      "\n",
      "Batch input :\n",
      " [ 2. 35. 49.  5. 53.] \n",
      "Batch target :\n",
      " [35. 49.  5. 53.  2.]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n##################### Sans noise #####################\")\n",
    "i = 0\n",
    "for batch_inputs, batch_targets in gen_batch(inputs, targets, seq_len=5, batch_size=32, noise=0): #Sequence de 5, batch de 32\n",
    "    i += 1\n",
    "    print(\"\\n----------------------Step \", i, \"----------------------\")\n",
    "    print(\"\\nBatch input :\\n\", batch_inputs.shape, \"\\nBatch target shape :\\n\", batch_targets.shape)\n",
    "    print(\"\\nBatch input :\\n\", batch_inputs[0], \"\\nBatch target :\\n\", batch_targets[0])\n",
    "    if i > 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##################### Avec noise = 3 #####################\n",
      "\n",
      "---------------------- Step  1  ----------------------\n",
      "\n",
      "Batch input :\n",
      " (32, 5) \n",
      "Batch target shape :\n",
      " (32, 5)\n",
      "\n",
      "Batch input :\n",
      " [31. 17. 29. 29. 29.] \n",
      "Batch target :\n",
      " [17. 24. 26.  5.  2.]\n",
      "\n",
      "---------------------- Step  2  ----------------------\n",
      "\n",
      "Batch input :\n",
      " (32, 5) \n",
      "Batch target shape :\n",
      " (32, 5)\n",
      "\n",
      "Batch input :\n",
      " [ 2. 13. 13. 13. 53.] \n",
      "Batch target :\n",
      " [35. 49.  5. 53.  2.]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n##################### Avec noise = 3 #####################\")\n",
    "i = 0\n",
    "for batch_inputs, batch_targets in gen_batch(inputs, targets, seq_len=5, batch_size=32, noise=3): #Sequence de 5, batch de 32\n",
    "    i += 1\n",
    "    print(\"\\n---------------------- Step \", i, \" ----------------------\")\n",
    "    print(\"\\nBatch input :\\n\", batch_inputs.shape, \"\\nBatch target shape :\\n\", batch_targets.shape)\n",
    "    print(\"\\nBatch input :\\n\", batch_inputs[0], \"\\nBatch target :\\n\", batch_targets[0])\n",
    "    if i > 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --> One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Les valeurs au dessus ne nous convienne pas pour entrainer un model il y a mieux.\n",
    "#On va donc utiliser le one hot encoding pour simplifier la tache à notre model.\n",
    "#Exemple de one hot encoding : a => 2 => [0, 1, 0, 0]\n",
    "#Le one hot encoding est tres efficace lorsqu'on veut specifier des classes.\n",
    "#En effet, il n'y a aucune raison qu'un nombres que nous donnons a un caractere\n",
    "#ait un nombre plus eleve et donc avec plus de poids qu'un autre alors qu'il n'y\n",
    "#a aucune hierarchie entre les caracteres.\n",
    "class OneHot(tf.keras.layers.Layer): #On creer une custom layer OneHot\n",
    "    \n",
    "    def __init__(self, depth, **kwargs):\n",
    "        super(OneHot, self).__init__(**kwargs)\n",
    "        self.depth = depth\n",
    "        \n",
    "    def call(self, x, mask=None):\n",
    "         #Transforme le x en int 32 et creer un vecteur one hot encoded\n",
    "        return tf.one_hot(tf.cast(x, tf.int32), self.depth)\n",
    "    \n",
    "    def get_config(self): #Override get_config pour pouvoir save le model\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'depth': self.depth,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input letter :\n",
      " 31.0\n",
      "Next letter prediction :\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "class RNNModel(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, vocab_size):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.one_hot = OneHot(len(vocab))\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        output_layer = self.one_hot(inputs)\n",
    "        return output_layer\n",
    "    \n",
    "batch_inputs, batch_targets = next(gen_batch(inputs, targets, seq_len=50, batch_size=32)) #32 sequences, 50 elements\n",
    "model = RNNModel(len(vocab))\n",
    "output = model.predict(batch_inputs)[0][0]\n",
    "\n",
    "print(\"Input letter :\\n\", batch_inputs[0][0])\n",
    "print(\"Next letter prediction :\\n\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --> Creation du model RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "\n",
    "#Input layer\n",
    "#On ne set pas le nombre d'element dans les sequences\n",
    "tf_inputs = tf.keras.Input(shape=(None,), batch_size=32) \n",
    "#One hot layer\n",
    "#En lui passant tf_inputs, on specifie la shape qu'on enverra dans la layer one_hot\n",
    "one_hot = OneHot(vocab_size)(tf_inputs) \n",
    "#LSTM layers\n",
    "#\"return_sequences\" permet de specifier que l'on prend en compte plusieurs des anciennes\n",
    "#cellules LSTM, si on met a False nous aurions que l'information de la derniere cellule LSTM\n",
    "#\"stateful\" permet de specifier qu'a chaque appel on ne va pas reinitialiser les cellules.\n",
    "#A chaque appel l'etat initial sera egal au dernier element de la sequence precedente\n",
    "rnn_layer1 = tf.keras.layers.LSTM(128, return_sequences=True, stateful=True)(one_hot) \n",
    "rnn_layer2 = tf.keras.layers.LSTM(128, return_sequences=True, stateful=True)(rnn_layer1)\n",
    "#Dense layer\n",
    "hidden_layer = tf.keras.layers.Dense(128, activation=\"relu\")(rnn_layer2)\n",
    "#Output layer\n",
    "output_layer = tf.keras.layers.Dense(vocab_size, activation=\"softmax\")(hidden_layer)\n",
    "\n",
    "#Model\n",
    "model = tf.keras.Model(inputs=tf_inputs, outputs=output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First prediction :\n",
      " [0.0175922  0.01755079 0.01758404 0.01756127 0.01746607 0.01760784\n",
      " 0.01756605 0.0175176  0.01746702 0.01754959 0.0174946  0.01754105\n",
      " 0.01754688 0.01754523 0.01757365 0.01753175 0.01750153 0.01756241\n",
      " 0.0175528  0.01750962 0.01759637 0.01758435 0.01750205 0.01752504\n",
      " 0.01762402 0.01750478 0.01752348 0.01755448 0.01755507 0.01755614\n",
      " 0.01752438 0.01752501 0.01755911 0.01761584 0.01760784 0.01751597\n",
      " 0.0174827  0.01754175 0.01757086 0.01754703 0.01747712 0.01755028\n",
      " 0.0175303  0.01752012 0.01752548 0.01755951 0.01750464 0.01755796\n",
      " 0.01758248 0.01748202 0.01758216 0.01755241 0.0175486  0.01758036\n",
      " 0.0175125  0.01750905 0.01758676]\n",
      "Second prediction :\n",
      " [0.0175922  0.01755079 0.01758404 0.01756127 0.01746607 0.01760784\n",
      " 0.01756605 0.0175176  0.01746702 0.01754959 0.0174946  0.01754105\n",
      " 0.01754688 0.01754523 0.01757365 0.01753175 0.01750153 0.01756241\n",
      " 0.0175528  0.01750962 0.01759637 0.01758435 0.01750205 0.01752504\n",
      " 0.01762402 0.01750478 0.01752348 0.01755448 0.01755507 0.01755614\n",
      " 0.01752438 0.01752501 0.01755911 0.01761584 0.01760784 0.01751597\n",
      " 0.0174827  0.01754175 0.01757086 0.01754703 0.01747712 0.01755028\n",
      " 0.0175303  0.01752012 0.01752548 0.01755951 0.01750464 0.01755796\n",
      " 0.01758248 0.01748202 0.01758216 0.01755241 0.0175486  0.01758036\n",
      " 0.0175125  0.01750905 0.01758676]\n"
     ]
    }
   ],
   "source": [
    "#Reset les cellules du RNN\n",
    "model.reset_states()\n",
    "\n",
    "#Creer un premier batch\n",
    "batch_inputs, target_inputs = next(gen_batch(inputs, targets, seq_len=50, batch_size=32))\n",
    "\n",
    "#Prediction pour un premier batch\n",
    "outputs = model.predict(batch_inputs)\n",
    "#Prediction de la premiere sortie\n",
    "first_prediction = outputs[0][0]\n",
    "print(\"First prediction :\\n\", first_prediction)\n",
    "\n",
    "model.reset_states()\n",
    "\n",
    "#Deuxieme prediction, c'est exactement la meme grace au stateful=True\n",
    "outputs = model.predict(batch_inputs)\n",
    "second_prediction = outputs[0][0]\n",
    "print(\"Second prediction :\\n\", second_prediction)\n",
    "\n",
    "#Check si les deux predictions sont egales avec un reset_state() entre les deux\n",
    "assert(set(first_prediction)==set(second_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam(lr=0.001) #lr : learning rate\n",
    "train_loss = tf.keras.metrics.Mean(name=\"train_loss\")\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        #Fait une prediction sur le batch\n",
    "        predictions = model(inputs)\n",
    "        #Recupere l'erreur par rapport aux predictions faites\n",
    "        loss = loss_object(targets, predictions)\n",
    "    #Calcul du gradient\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    #Change les poids du model grace au gradient\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    #Garde l'information sur l'evolution de l'entrainement\n",
    "    train_loss(loss)\n",
    "    train_accuracy(targets, predictions)\n",
    "\n",
    "@tf.function\n",
    "def predict(inputs):\n",
    "    # Fait une prediction sur tous le batch\n",
    "    predictions = model(inputs)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --> Entrainement du model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(32, None)]              0         \n",
      "_________________________________________________________________\n",
      "one_hot_1 (OneHot)           (32, None, 57)            0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (32, None, 128)           95232     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (32, None, 128)           131584    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (32, None, 128)           16512     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (32, None, 57)            7353      \n",
      "=================================================================\n",
      "Total params: 250,681\n",
      "Trainable params: 250,681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " Epoch 9, Train Loss: 2.650911808013916, Train Accuracy: 24.4056091308593755"
     ]
    }
   ],
   "source": [
    "model.reset_states()\n",
    "\n",
    "model.summary()\n",
    "\n",
    "for epoch in range(10):\n",
    "    #Pendant toute cette etape dans le for, on ne reinitialise pas les states\n",
    "    for batch_inputs, batch_targets in gen_batch(inputs, targets, seq_len=100, batch_size=32, noise=13): #Sequence de taille 100, batch de 32\n",
    "        train_step(batch_inputs, batch_targets)\n",
    "    template = '\\r Epoch {}, Train Loss: {}, Train Accuracy: {}'\n",
    "    print(template.format(epoch, \n",
    "                          train_loss.result(), \n",
    "                          train_accuracy.result()*100), end=\"\")\n",
    "    model.reset_states() #On reinitialise le state pour la prochaine epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --> Sauveguarde du model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "model.save(\"model_rnn.h5\")\n",
    "\n",
    "with open(\"model_rnn_vocab_to_int\", \"w\") as f:\n",
    "    f.write(json.dumps(vocab_to_int))\n",
    "with open(\"model_rnn_int_to_vocab\", \"w\") as f:\n",
    "    f.write(json.dumps(int_to_vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --> Generation de poeme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e le cous le cous le coure et le poure \n",
      "\n",
      "Le cous le cous le cous le coure et le mes le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le \n",
      "\n",
      "=====================\n",
      "\n",
      " le coure et le poure \n",
      "\n",
      "Le cous le cous le cous le coure et le mes le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le\n",
      "\n",
      "=====================\n",
      "\n",
      "es le mes le mes le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le l\n",
      "\n",
      "=====================\n",
      "\n",
      " le mes le mes le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le \n",
      "\n",
      "=====================\n",
      "\n",
      "es le poure et le poure \n",
      "\n",
      "Le cous le cous le cous le coure et le mes le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le \n",
      "\n",
      "=====================\n",
      "\n",
      "e poure et le poure \n",
      "\n",
      "Le cous le cous le cous le coure et le mes le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le l\n",
      "\n",
      "=====================\n",
      "\n",
      " le cous le cous le coure et le poure \n",
      "\n",
      "Le cous le cous le cous le coure et le poure \n",
      "\n",
      "Le cous le cous le cous le coure et le poure \n",
      "\n",
      "Le cous le cous le cous le coure et le poure \n",
      "\n",
      "Le cous le cous le cous le coure et le poure \n",
      "\n",
      "Le cous le cous le cous le coure et le poure \n",
      "\n",
      "Le cous le cous le cous l\n",
      "\n",
      "=====================\n",
      "\n",
      " le ces le ces le coure et le poure \n",
      "\n",
      "Le cous le cous le cous le coure et le poure \n",
      "\n",
      "Le cous le cous le cous le coure et le poure \n",
      "\n",
      "Le cous le cous le cous le coure et le poure \n",
      "\n",
      "Le cous le cous le cous le coure et le poure \n",
      "\n",
      "Le cous le cous le cous le coure et le poure \n",
      "\n",
      "Le cous le cous le cous le \n",
      "\n",
      "=====================\n",
      "\n",
      " ces le poure \n",
      "\n",
      "Le cous le cous le cous le coure et le poure \n",
      "\n",
      "Le cous le cous le cous le coure et le poure \n",
      "\n",
      "Le cous le cous le cous le coure et le poure \n",
      "\n",
      "Le cous le cous le cous le coure et le poure \n",
      "\n",
      "Le cous le cous le cous le coure et le poure \n",
      "\n",
      "Le cous le cous le cous le coure et le poure \n",
      "\n",
      "Le\n",
      "\n",
      "=====================\n",
      "\n",
      " cous le mes le mes le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le l\n",
      "\n",
      "=====================\n",
      "\n",
      "e de ces le ces le poure et le poure \n",
      "\n",
      "Le cous le cous le cous le coure et le mes le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le\n",
      "\n",
      "=====================\n",
      "\n",
      "et le poure \n",
      "\n",
      "Le cous le cous le cous le coure et le poure \n",
      "\n",
      "Le cous le cous le cous le coure et le poure \n",
      "\n",
      "Le cous le cous le cous le coure et le poure \n",
      "\n",
      "Le cous le cous le cous le coure et le poure \n",
      "\n",
      "Le cous le cous le cous le coure et le poure \n",
      "\n",
      "Le cous le cous le cous le coure et le poure \n",
      "\n",
      "Le c\n",
      "\n",
      "=====================\n",
      "\n",
      "es le mes le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le\n",
      "\n",
      "=====================\n",
      "\n",
      " les le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le l\n",
      "\n",
      "=====================\n",
      "\n",
      " de le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le\n",
      "\n",
      "=====================\n",
      "\n",
      "e ces le ces le ces le poure et le poure \n",
      "\n",
      "Le cous le cous le cous le coure et le poure \n",
      "\n",
      "Le cous le cous le cous le coure et le poure \n",
      "\n",
      "Le cous le cous le cous le coure et le poure \n",
      "\n",
      "Le cous le cous le cous le coure et le poure \n",
      "\n",
      "Le cous le cous le cous le coure et le poure \n",
      "\n",
      "Le cous le cous le cou\n",
      "\n",
      "=====================\n",
      "\n",
      " le cous le cous le coure et le poure \n",
      "\n",
      "Le cous le cous le cous le coure et le poure \n",
      "\n",
      "Le cous le cous le cous le coure et le poure \n",
      "\n",
      "Le cous le cous le cous le coure et le poure \n",
      "\n",
      "Le cous le cous le cous le coure et le poure \n",
      "\n",
      "Le cous le cous le cous le coure et le poure \n",
      "\n",
      "Le cous le cous le cous l\n",
      "\n",
      "=====================\n",
      "\n",
      "es le coure et le poure \n",
      "\n",
      "Le cous le cous le cous le coure et le poure \n",
      "\n",
      "Le cous le cous le cous le coure et le poure \n",
      "\n",
      "Le cous le cous le cous le coure et le poure \n",
      "\n",
      "Le cous le cous le cous le coure et le poure \n",
      "\n",
      "Le cous le cous le cous le coure et le poure \n",
      "\n",
      "Le cous le cous le cous le coure et le \n",
      "\n",
      "=====================\n",
      "\n",
      "te de coure et le poure \n",
      "\n",
      "Le cous le cous le cous le coure et le poure \n",
      "\n",
      "Le cous le cous le cous le coure et le poure \n",
      "\n",
      "Le cous le cous le cous le coure et le poure \n",
      "\n",
      "Le cous le cous le cous le coure et le poure \n",
      "\n",
      "Le cous le cous le cous le coure et le poure \n",
      "\n",
      "Le cous le cous le cous le coure et le \n",
      "\n",
      "=====================\n",
      "\n",
      "L de ces le ces le ces le poure et le poure \n",
      "\n",
      "Le cous le cous le cous le coure et le mes le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le l\n",
      "\n",
      "=====================\n",
      "\n",
      " et le mes le mes le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le \n",
      "\n",
      "=====================\n",
      "\n",
      "t le poure \n",
      "\n",
      "Le cous le cous le cous le coure et le mes le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le l\n",
      "\n",
      "=====================\n",
      "\n",
      " sour de poure et le poure \n",
      "\n",
      "Le cous le cous le cous le coure et le mes le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le \n",
      "\n",
      "=====================\n",
      "\n",
      " de ces le poure et le poure \n",
      "\n",
      "Le cous le cous le cous le coure et le mes le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le l\n",
      "\n",
      "=====================\n",
      "\n",
      " les le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le l\n",
      "\n",
      "=====================\n",
      "\n",
      " le ces le poure et le poure \n",
      "\n",
      "Le cous le cous le cous le coure et le mes le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le l\n",
      "\n",
      "=====================\n",
      "\n",
      "es le mes le poure \n",
      "\n",
      "Le cous le cous le cous le coure et le mes le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le\n",
      "\n",
      "=====================\n",
      "\n",
      "e ces le ces le coure et le mes le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le l\n",
      "\n",
      "=====================\n",
      "\n",
      "e le poure et le poure \n",
      "\n",
      "Le cous le cous le cous le coure et le poure \n",
      "\n",
      "Le cous le cous le cous le coure et le poure \n",
      "\n",
      "Le cous le cous le cous le coure et le poure \n",
      "\n",
      "Le cous le cous le cous le coure et le poure \n",
      "\n",
      "Le cous le cous le cous le coure et le poure \n",
      "\n",
      "Le cous le cous le cous le coure et le p\n",
      "\n",
      "=====================\n",
      "\n",
      " ces le coure et le mes le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le \n",
      "\n",
      "=====================\n",
      "\n",
      " de ces le ces le poure et le poure \n",
      "\n",
      "Le cous le cous le cous le coure et le mes le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le \n",
      "\n",
      "=====================\n",
      "\n",
      "et le poure \n",
      "\n",
      "Le cous le cous le cous le coure et le poure \n",
      "\n",
      "Le cous le cous le cous le coure et le poure \n",
      "\n",
      "Le cous le cous le cous le coure et le poure \n",
      "\n",
      "Le cous le cous le cous le coure et le poure \n",
      "\n",
      "Le cous le cous le cous le coure et le poure \n",
      "\n",
      "Le cous le cous le cous le coure et le poure \n",
      "\n",
      "Le c\n",
      "\n",
      "=====================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "model.reset_states()\n",
    "\n",
    "size_poetries = 300\n",
    "\n",
    "poetries = np.zeros((32, size_poetries, 1))\n",
    "sequences = np.zeros((32, 100))\n",
    "for b in range(32):\n",
    "    rd = np.random.randint(0, len(inputs) - 100)\n",
    "    sequences[b] = inputs[rd:rd+100]\n",
    "\n",
    "for i in range(size_poetries+1):\n",
    "    if i > 0:\n",
    "        poetries[:,i-1,:] = sequences\n",
    "    softmax = predict(sequences)\n",
    "    # Set the next sequences\n",
    "    sequences = np.zeros((32, 1))\n",
    "    for b in range(32):\n",
    "        argsort = np.argsort(softmax[b][0])\n",
    "        argsort = argsort[::-1]\n",
    "        # Select one of the strongest 4 proposals\n",
    "        sequences[b] = argsort[0]\n",
    "\n",
    "for b in range(32):\n",
    "    sentence = \"\".join([int_to_vocab[i[0]] for i in poetries[b]])\n",
    "    print(sentence)\n",
    "    print(\"\\n=====================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow-gpu-jupyter]",
   "language": "python",
   "name": "conda-env-tensorflow-gpu-jupyter-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
