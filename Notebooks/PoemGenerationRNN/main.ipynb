{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --> Importations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --> Importation dataset poeme de Victor Hugo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille du text :  127286\n",
      "Texte avant preprocessing :\n",
      " Parce que, jargonnant vêpres, jeûne et vigile,\n",
      "Exploitant Dieu qui rêve au fond du firmament,\n",
      "Vous a\n"
     ]
    }
   ],
   "source": [
    "with open(\"../../Datasets/VictorHugoPoems/victorhugo.txt\", \"r\", encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "    \n",
    "print(\"Taille du text : \", len(text))\n",
    "print(\"Texte avant preprocessing :\\n\", text[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --> Preprocessing du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille du vocabulaire :  57\n",
      "Vocabulaire :\n",
      " {'b', 'M', 'i', 'O', 'U', 'k', 'r', 't', 'E', 'P', 'l', 'u', 'T', 'Y', '.', \"'\", 'e', 'S', 'a', 'J', ',', 'g', 'z', 'm', 'y', 'G', 'c', 'Q', 'C', 'L', ':', 's', 'p', 'n', 'V', 'x', '\"', '\\n', 'd', 'h', 'R', 'H', 'w', 'j', 'X', 'K', 'o', 'v', 'B', 'f', 'N', 'D', 'I', 'A', ' ', 'F', 'q'}\n",
      "Texte formate :\n",
      " Parce que, jargonnant vepres, jeune et vigile,\n",
      "Exploitant Dieu qui reve au fond du firmament,\n",
      "Vous a\n"
     ]
    }
   ],
   "source": [
    "#Supprime les caracteres inutiles, les majuscules...\n",
    "import unidecode\n",
    "text = unidecode.unidecode(text)\n",
    "text.lower()\n",
    "text = text.replace(\"2\", \"\")\n",
    "text = text.replace(\"1\", \"\")\n",
    "text = text.replace(\"8\", \"\")\n",
    "text = text.replace(\"5\", \"\")\n",
    "text = text.replace(\">\", \"\")\n",
    "text = text.replace(\"<\", \"\")\n",
    "text = text.replace(\"!\", \"\")\n",
    "text = text.replace(\"?\", \"\")\n",
    "text = text.replace(\"-\", \"\")\n",
    "text = text.replace(\"$\", \"\")\n",
    "text = text.replace(\";\", \"\")\n",
    "text = text.strip()\n",
    "\n",
    "#Supprime tous les doublons\n",
    "vocab = set(text) \n",
    "\n",
    "#Affichage resultat\n",
    "print(\"Taille du vocabulaire : \", len(vocab))\n",
    "print(\"Vocabulaire :\\n\", vocab)\n",
    "print(\"Texte formate :\\n\", text[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab to int :\n",
      " {'b': 0, 'M': 1, 'i': 2, 'O': 3, 'U': 4, 'k': 5, 'r': 6, 't': 7, 'E': 8, 'P': 9, 'l': 10, 'u': 11, 'T': 12, 'Y': 13, '.': 14, \"'\": 15, 'e': 16, 'S': 17, 'a': 18, 'J': 19, ',': 20, 'g': 21, 'z': 22, 'm': 23, 'y': 24, 'G': 25, 'c': 26, 'Q': 27, 'C': 28, 'L': 29, ':': 30, 's': 31, 'p': 32, 'n': 33, 'V': 34, 'x': 35, '\"': 36, '\\n': 37, 'd': 38, 'h': 39, 'R': 40, 'H': 41, 'w': 42, 'j': 43, 'X': 44, 'K': 45, 'o': 46, 'v': 47, 'B': 48, 'f': 49, 'N': 50, 'D': 51, 'I': 52, 'A': 53, ' ': 54, 'F': 55, 'q': 56}\n",
      "Int to vocab :\n",
      " {0: 'b', 1: 'M', 2: 'i', 3: 'O', 4: 'U', 5: 'k', 6: 'r', 7: 't', 8: 'E', 9: 'P', 10: 'l', 11: 'u', 12: 'T', 13: 'Y', 14: '.', 15: \"'\", 16: 'e', 17: 'S', 18: 'a', 19: 'J', 20: ',', 21: 'g', 22: 'z', 23: 'm', 24: 'y', 25: 'G', 26: 'c', 27: 'Q', 28: 'C', 29: 'L', 30: ':', 31: 's', 32: 'p', 33: 'n', 34: 'V', 35: 'x', 36: '\"', 37: '\\n', 38: 'd', 39: 'h', 40: 'R', 41: 'H', 42: 'w', 43: 'j', 44: 'X', 45: 'K', 46: 'o', 47: 'v', 48: 'B', 49: 'f', 50: 'N', 51: 'D', 52: 'I', 53: 'A', 54: ' ', 55: 'F', 56: 'q'}\n"
     ]
    }
   ],
   "source": [
    "#On traduit maintenant tout le vocabulaire en nombre\n",
    "vocab_size = len(vocab)\n",
    "#Dictionnaire traduction\n",
    "vocab_to_int = {l:i for i,l in enumerate(vocab)} \n",
    "int_to_vocab = {i:l for i,l in enumerate(vocab)}\n",
    "#Affichage\n",
    "print(\"Vocab to int :\\n\", vocab_to_int)\n",
    "print(\"Int to vocab :\\n\", int_to_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 18, 6, 26, 16, 54, 56, 11, 16, 20, 54, 43, 18, 6, 21, 46, 33, 33, 18, 33, 7, 54, 47, 16, 32, 6, 16, 31, 20, 54, 43, 16, 11, 33, 16, 54, 16, 7, 54, 47, 2, 21, 2, 10, 16, 20, 37, 8, 35, 32, 10, 46, 2, 7, 18, 33, 7, 54, 51, 2, 16, 11, 54, 56, 11, 2, 54, 6, 16, 47, 16, 54, 18, 11, 54, 49, 46, 33, 38, 54, 38, 11, 54, 49, 2, 6, 23, 18, 23, 16, 33, 7, 20, 37, 34, 46, 11, 31, 54, 18]\n"
     ]
    }
   ],
   "source": [
    "#Le dictionnaire nous permet de traduire notre text en nombre\n",
    "encoded = [vocab_to_int[l] for l in text]\n",
    "encoded_sentence = encoded[:100]\n",
    "print(encoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['P', 'a', 'r', 'c', 'e', ' ', 'q', 'u', 'e', ',', ' ', 'j', 'a', 'r', 'g', 'o', 'n', 'n', 'a', 'n', 't', ' ', 'v', 'e', 'p', 'r', 'e', 's', ',', ' ', 'j', 'e', 'u', 'n', 'e', ' ', 'e', 't', ' ', 'v', 'i', 'g', 'i', 'l', 'e', ',', '\\n', 'E', 'x', 'p', 'l', 'o', 'i', 't', 'a', 'n', 't', ' ', 'D', 'i', 'e', 'u', ' ', 'q', 'u', 'i', ' ', 'r', 'e', 'v', 'e', ' ', 'a', 'u', ' ', 'f', 'o', 'n', 'd', ' ', 'd', 'u', ' ', 'f', 'i', 'r', 'm', 'a', 'm', 'e', 'n', 't', ',', '\\n', 'V', 'o', 'u', 's', ' ', 'a']\n"
     ]
    }
   ],
   "source": [
    "decoded_sentence = [int_to_vocab[i] for i in encoded_sentence]\n",
    "print(decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parce que, jargonnant vepres, jeune et vigile,\n",
      "Exploitant Dieu qui reve au fond du firmament,\n",
      "Vous a\n"
     ]
    }
   ],
   "source": [
    "decoded_sentence = \"\".join(decoded_sentence)\n",
    "print(decoded_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --> Creation des batchs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First inputs :  [9, 18, 6, 26, 16, 54, 56, 11, 16, 20]\n",
      "First targets :  [18, 6, 26, 16, 54, 56, 11, 16, 20, 54]\n"
     ]
    }
   ],
   "source": [
    "#Un batch = plusieurs sequences de mots\n",
    "#Ce qu'on peut faire lorsqu'on a un dataset comme cela, on peut prendre une sequence de quelques mots\n",
    "#Chaque lettre est une entree dont le target est la lettre suivante. \n",
    "#Une incoherence peut arriver lors de l'analyse de la premiere lettre d'une sequence\n",
    "#Car dans notre cellule RNN il n'a pas d'informations sur la lettre precedente car la memoire est nulle.\n",
    "#Au lieu de lui mettre un etat nulle on lui mets l'etat retenu du batch precendent.\n",
    "#On ne peut donc pas se permettre de selectionner des sequences aleatoires dans notre texte.\n",
    "#On va donc seprarer notre texte en chunks\n",
    "#Une epoch : un ensemble de batch\n",
    "def gen_batch(inputs, targets, seq_len, batch_size, noise=0):\n",
    "    \n",
    "    chunk_size = (len(inputs) -1) // batch_size\n",
    "    sequences_per_chunk = chunk_size // seq_len\n",
    "    \n",
    "    for seq in range(0, sequences_per_chunk):\n",
    "        batch_inputs = np.zeros((batch_size, seq_len))\n",
    "        batch_targets = np.zeros((batch_size, seq_len))\n",
    "        for b in range(0, batch_size):\n",
    "            fr = (b*chunk_size) + (seq*seq_len)\n",
    "            to = fr + seq_len\n",
    "            batch_inputs[b] = inputs[fr:to]\n",
    "            batch_targets[b] = inputs[fr+1:to+1]\n",
    "\n",
    "            if noise > 0: #\"noise\" aide le model a generaliser, evite l'overfitting\n",
    "                noise_indices = np.random.choice(seq_len, noise)\n",
    "                batch_inputs[b][noise_indices] = np.random.randint(0, vocab_size)\n",
    "\n",
    "        yield batch_inputs, batch_targets #Permet d'appeler la fonction dans la boucle\n",
    "            \n",
    "inputs, targets = encoded, encoded[1:]\n",
    "print(\"First inputs : \", inputs[:10])\n",
    "print(\"First targets : \", targets[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##################### Sans noise #####################\n",
      "\n",
      "----------------------Step  1 ----------------------\n",
      "\n",
      "Batch input :\n",
      " (64, 5) \n",
      "Batch target shape :\n",
      " (64, 5)\n",
      "\n",
      "Batch input :\n",
      " [ 9. 18.  6. 26. 16.] \n",
      "Batch target :\n",
      " [18.  6. 26. 16. 54.]\n",
      "\n",
      "----------------------Step  2 ----------------------\n",
      "\n",
      "Batch input :\n",
      " (64, 5) \n",
      "Batch target shape :\n",
      " (64, 5)\n",
      "\n",
      "Batch input :\n",
      " [54. 56. 11. 16. 20.] \n",
      "Batch target :\n",
      " [56. 11. 16. 20. 54.]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n##################### Sans noise #####################\")\n",
    "i = 0\n",
    "for batch_inputs, batch_targets in gen_batch(inputs, targets, 5, 64, noise=0): #Sequence de 5, batch de 32\n",
    "    i += 1\n",
    "    print(\"\\n----------------------Step \", i, \"----------------------\")\n",
    "    print(\"\\nBatch input :\\n\", batch_inputs.shape, \"\\nBatch target shape :\\n\", batch_targets.shape)\n",
    "    print(\"\\nBatch input :\\n\", batch_inputs[0], \"\\nBatch target :\\n\", batch_targets[0])\n",
    "    if i > 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##################### Avec noise = 3 #####################\n",
      "\n",
      "---------------------- Step  1  ----------------------\n",
      "\n",
      "Batch input :\n",
      " (64, 5) \n",
      "Batch target shape :\n",
      " (64, 5)\n",
      "\n",
      "Batch input :\n",
      " [40. 40.  6. 26. 16.] \n",
      "Batch target :\n",
      " [18.  6. 26. 16. 54.]\n",
      "\n",
      "---------------------- Step  2  ----------------------\n",
      "\n",
      "Batch input :\n",
      " (64, 5) \n",
      "Batch target shape :\n",
      " (64, 5)\n",
      "\n",
      "Batch input :\n",
      " [54. 41. 11. 41. 20.] \n",
      "Batch target :\n",
      " [56. 11. 16. 20. 54.]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n##################### Avec noise = 3 #####################\")\n",
    "i = 0\n",
    "for batch_inputs, batch_targets in gen_batch(inputs, targets, 5, 64, noise=3): #Sequence de 5, batch de 32\n",
    "    i += 1\n",
    "    print(\"\\n---------------------- Step \", i, \" ----------------------\")\n",
    "    print(\"\\nBatch input :\\n\", batch_inputs.shape, \"\\nBatch target shape :\\n\", batch_targets.shape)\n",
    "    print(\"\\nBatch input :\\n\", batch_inputs[0], \"\\nBatch target :\\n\", batch_targets[0])\n",
    "    if i > 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --> One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Les valeurs au dessus ne nous convienne pas pour entrainer un model il y a mieux.\n",
    "#On va donc utiliser le one hot encoding pour simplifier la tache à notre model.\n",
    "#Exemple de one hot encoding : a => 2 => [0, 1, 0, 0]\n",
    "#Le one hot encoding est tres efficace lorsqu'on veut specifier des classes.\n",
    "#En effet, il n'y a aucune raison qu'un nombres que nous donnons a un caractere\n",
    "#ait un nombre plus eleve et donc avec plus de poids qu'un autre alors qu'il n'y\n",
    "#a aucune hierarchie entre les caracteres.\n",
    "class OneHot(tf.keras.layers.Layer): #On creer une custom layer OneHot\n",
    "    \n",
    "    def __init__(self, depth, **kwargs):\n",
    "        super(OneHot, self).__init__(**kwargs)\n",
    "        self.depth = depth\n",
    "        \n",
    "    def call(self, x, mask=None):\n",
    "         #Transforme le x en int 32 et creer un vecteur one hot encoded\n",
    "        return tf.one_hot(tf.cast(x, tf.int32), self.depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input letter :\n",
      " 9.0\n",
      "Next letter prediction :\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "class RNNModel(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, vocab_size):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.one_hot = OneHot(len(vocab))\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        output_layer = self.one_hot(inputs)\n",
    "        return output_layer\n",
    "    \n",
    "batch_inputs, batch_targets = next(gen_batch(inputs, targets, 50, 64)) #32 sequences, 50 elements\n",
    "model = RNNModel(len(vocab))\n",
    "output = model.predict(batch_inputs)[0][0]\n",
    "\n",
    "print(\"Input letter :\\n\", batch_inputs[0][0])\n",
    "print(\"Next letter prediction :\\n\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --> Creation du model RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "\n",
    "#Input layer\n",
    "#On ne set pas le nombre d'element dans les sequences\n",
    "tf_inputs = tf.keras.Input(shape=(None,), batch_size=64) \n",
    "#One hot layer\n",
    "#En lui passant tf_inputs, on specifie la shape qu'on enverra dans la layer one_hot\n",
    "one_hot = OneHot(vocab_size)(tf_inputs) \n",
    "#LSTM layers\n",
    "#\"return_sequences\" permet de specifier que l'on prend en compte plusieurs des anciennes\n",
    "#cellules LSTM, si on met a False nous aurions que l'information de la derniere cellule LSTM\n",
    "#\"stateful\" permet de specifier qu'a chaque appel on ne va pas reinitialiser les cellules.\n",
    "#A chaque appel l'etat initial sera egal au dernier element de la sequence precedente\n",
    "rnn_layer1 = tf.keras.layers.LSTM(128, return_sequences=True, stateful=True)(one_hot) \n",
    "rnn_layer2 = tf.keras.layers.LSTM(128, return_sequences=True, stateful=True)(rnn_layer1)\n",
    "#Dense layer\n",
    "hidden_layer = tf.keras.layers.Dense(128, activation=\"relu\")(rnn_layer2)\n",
    "#Output layer\n",
    "output_layer = tf.keras.layers.Dense(vocab_size, activation=\"softmax\")(hidden_layer)\n",
    "\n",
    "#Model\n",
    "model = tf.keras.Model(inputs=tf_inputs, outputs=output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (64, None) for input KerasTensor(type_spec=TensorSpec(shape=(64, None), dtype=tf.float32, name='input_6'), name='input_6', description=\"created by layer 'input_6'\"), but it was called on an input with incompatible shape (32, 50).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\karna\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1478 predict_function  *\n        return step_function(self, iterator)\n    C:\\Users\\karna\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1468 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\karna\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\karna\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\karna\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\karna\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1461 run_step  **\n        outputs = model.predict_step(data)\n    C:\\Users\\karna\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1434 predict_step\n        return self(x, training=False)\n    C:\\Users\\karna\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:1012 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    C:\\Users\\karna\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:424 call\n        return self._run_internal_graph(\n    C:\\Users\\karna\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:560 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    C:\\Users\\karna\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py:660 __call__\n        return super(RNN, self).__call__(inputs, **kwargs)\n    C:\\Users\\karna\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    C:\\Users\\karna\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:271 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) +\n\n    ValueError: Input 0 is incompatible with layer lstm_10: expected shape=(64, None, 57), found shape=(32, 50, 57)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-104-24bcac590a5f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#Prediction pour un premier batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;31m#Prediction de la premiere sortie\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mfirst_prediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1627\u001b[0m           \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1628\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1629\u001b[1;33m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1630\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1631\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    869\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 871\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    872\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    873\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    723\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m--> 725\u001b[1;33m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    726\u001b[0m             *args, **kwds))\n\u001b[0;32m    727\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2968\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2969\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2970\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2971\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3361\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3194\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3195\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3196\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3197\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3198\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    989\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 990\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    991\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    992\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    633\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 634\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    635\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    975\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    976\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 977\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    978\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    979\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\karna\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1478 predict_function  *\n        return step_function(self, iterator)\n    C:\\Users\\karna\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1468 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\karna\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\karna\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\karna\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\karna\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1461 run_step  **\n        outputs = model.predict_step(data)\n    C:\\Users\\karna\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1434 predict_step\n        return self(x, training=False)\n    C:\\Users\\karna\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:1012 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    C:\\Users\\karna\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:424 call\n        return self._run_internal_graph(\n    C:\\Users\\karna\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:560 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    C:\\Users\\karna\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py:660 __call__\n        return super(RNN, self).__call__(inputs, **kwargs)\n    C:\\Users\\karna\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    C:\\Users\\karna\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:271 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) +\n\n    ValueError: Input 0 is incompatible with layer lstm_10: expected shape=(64, None, 57), found shape=(32, 50, 57)\n"
     ]
    }
   ],
   "source": [
    "#Reset les cellules du RNN\n",
    "model.reset_states()\n",
    "\n",
    "#Creer un premier batch\n",
    "batch_inputs, target_inputs = next(gen_batch(inputs, targets, 50, 64))\n",
    "\n",
    "#Prediction pour un premier batch\n",
    "outputs = model.predict(batch_inputs)\n",
    "#Prediction de la premiere sortie\n",
    "first_prediction = outputs[0][0]\n",
    "print(\"First prediction :\\n\", first_prediction)\n",
    "\n",
    "model.reset_states()\n",
    "\n",
    "#Deuxieme prediction, c'est exactement la meme grace au stateful=True\n",
    "outputs = model.predict(batch_inputs)\n",
    "second_prediction = outputs[0][0]\n",
    "print(\"Second prediction :\\n\", second_prediction)\n",
    "\n",
    "#Check si les deux predictions sont egales avec un reset_state() entre les deux\n",
    "assert(set(first_prediction)==set(second_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam(lr=0.001) #lr : learning rate\n",
    "train_loss = tf.keras.metrics.Mean(name=\"train_loss\")\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        #Fait une prediction sur le batch\n",
    "        predictions = model(inputs)\n",
    "        #Recupere l'erreur par rapport aux predictions faites\n",
    "        loss = loss_object(targets, predictions)\n",
    "    #Calcul du gradient\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    #Change les poids du model grace au gradient\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    #Garde l'information sur l'evolution de l'entrainement\n",
    "    train_loss(loss)\n",
    "    train_accuracy(targets, predictions)\n",
    "\n",
    "@tf.function\n",
    "def predict(inputs):\n",
    "    # Fait une prediction sur tous le batch\n",
    "    predictions = model(inputs)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --> Entrainement du model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(64, None)]              0         \n",
      "_________________________________________________________________\n",
      "one_hot_11 (OneHot)          (64, None, 57)            0         \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (64, None, 128)           95232     \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (64, None, 128)           131584    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (64, None, 128)           16512     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (64, None, 57)            7353      \n",
      "=================================================================\n",
      "Total params: 250,681\n",
      "Trainable params: 250,681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " Epoch 14, Train Loss: 2.916048765182495, Train Accuracy: 19.3752193450927733"
     ]
    }
   ],
   "source": [
    "model.reset_states()\n",
    "\n",
    "model.summary()\n",
    "\n",
    "for epoch in range(4000):\n",
    "    #Pendant toute cette etape dans le for, on ne reinitialise pas les states\n",
    "    for batch_inputs, batch_targets in gen_batch(inputs, targets, 100, 64, noise=13): #Sequence de taille 100, batch de 64\n",
    "        train_step(batch_inputs, batch_targets)\n",
    "    template = '\\r Epoch {}, Train Loss: {}, Train Accuracy: {}'\n",
    "    print(template.format(epoch, \n",
    "                          train_loss.result(), \n",
    "                          train_accuracy.result()*100), end=\"\")\n",
    "    model.reset_states() #On reinitialise le state pour la prochaine epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --> Sauveguarde du model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "model.save(\"model_rnn.h5\")\n",
    "\n",
    "with open(\"model_rnn_vocab_to_int\", \"w\") as f:\n",
    "    f.write(json.dumps(vocab_to_int))\n",
    "with open(\"model_rnn_int_to_vocab\", \"w\") as f:\n",
    "    f.write(json.dumps(int_to_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow-gpu]",
   "language": "python",
   "name": "conda-env-tensorflow-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
